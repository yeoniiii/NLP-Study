{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyKoSpacing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 띄어쓰기가 되어있지 않은 문장을 띄어쓰기 한 문장으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "김철수는극중두인격의사나이이광수역을맡았다.철수는한국유일의태권도전승자를가리는결전의날을앞두고10년간함께훈련한사형인유연재(김광수분)를찾으러속세로내려온인물이다.\n"
     ]
    }
   ],
   "source": [
    "sent = '김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.'\n",
    "new_sent = sent.replace(\" \", '') # 띄어쓰기가 없는 문장 임의로 만들기\n",
    "print(new_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.\n",
      "김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.\n"
     ]
    }
   ],
   "source": [
    "from pykospacing import Spacing\n",
    "spacing = Spacing()\n",
    "kospacing_sent = spacing(new_sent) \n",
    "\n",
    "print(sent)\n",
    "print(kospacing_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Py-Hanspell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 네이버 맞춤법 검사기 기반 맞춤법, 띄어쓰기 보정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/Seokhyeon-Park/hanspell.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "맞춤법 틀리면 왜 안돼? 쓰고 싶은 대로 쓰면 되지 \n"
     ]
    }
   ],
   "source": [
    "from hanspell import spell_checker\n",
    "\n",
    "sent = \"맞춤법틀리면외않되? 쓰고싶은대로쓰면돼지 \"\n",
    "spelled_sent = spell_checker.check(sent)\n",
    "\n",
    "hanspell_sent = spelled_sent.checked\n",
    "print(hanspell_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SoyNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단어 토크나이저 (품사 태깅, 단어 토큰화 등 지원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install soynlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 기존 형태소 분석기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['에이', '비식스', '이대', '휘', '1월', '최애', '돌', '기부', '요정']\n",
      "['크러쉬', '원더', '러스트', '명반', '이다']\n",
      "['메', '연', '이', '는', '딥', '러닝', '공부', '중']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "tokenizer = Okt()\n",
    "print(tokenizer.morphs('에이비식스 이대휘 1월 최애돌 기부 요정'))\n",
    "print(tokenizer.morphs('크러쉬 원더러스트 명반이다'))\n",
    "print(tokenizer.morphs('메연이는 딥러닝 공부 중'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2016-10-20.txt', <http.client.HTTPMessage at 0x2d95cb5e0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "from soynlp import DoublespaceLineCorpus\n",
    "from soynlp.word import WordExtractor\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/lovit/soynlp/master/tutorials/2016-10-20.txt\", filename=\"2016-10-20.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30091"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 데이터를 다수의 문서로 분리\n",
    "corpus = DoublespaceLineCorpus(\"2016-10-20.txt\")\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.690 Gb\n",
      "all cohesion probabilities was computed. # words = 223348\n",
      "all branching entropies was computed # words = 361598\n",
      "all accessor variety was computed # words = 361598\n"
     ]
    }
   ],
   "source": [
    "# 학습하기\n",
    "word_extractor = WordExtractor()\n",
    "word_extractor.train(corpus)\n",
    "word_score_table = word_extractor.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. SOYNLP의 응집 확률 cohesion probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08838002913645132\n",
      "0.19841268168224552\n",
      "0.37891487632839754\n",
      "0.33492963377557666\n"
     ]
    }
   ],
   "source": [
    "print(word_score_table[\"반포한\"].cohesion_forward)\n",
    "print(word_score_table[\"반포한강\"].cohesion_forward)\n",
    "print(word_score_table[\"반포한강공원\"].cohesion_forward)\n",
    "print(word_score_table[\"반포한강공원에\"].cohesion_forward)\n",
    "# 응집 확률이 가장 높은 반포한강공원이 하나의 단어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SOYNLP의 브랜칭 엔트로피 branching entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6371694761537934\n",
      "-0.0\n",
      "-0.0\n",
      "3.1400392861792916\n"
     ]
    }
   ],
   "source": [
    "print(word_score_table[\"디스\"].right_branching_entropy)\n",
    "print(word_score_table[\"디스플\"].right_branching_entropy)\n",
    "print(word_score_table[\"디스플레\"].right_branching_entropy)\n",
    "print(word_score_table[\"디스플레이\"].right_branching_entropy) # 다시 증가 -> 아 이게 단어 !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. SOYNLP의 L tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('국제사회', '와'), ('우리', '의'), ('노력', '들로'), ('범죄', '를'), ('척결', '하자')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.tokenizer import LTokenizer\n",
    "\n",
    "scores = {word:score.cohesion_forward for word, score in word_score_table.items()}\n",
    "l_tokenizer = LTokenizer(scores=scores)\n",
    "l_tokenizer.tokenize(\"국제사회와 우리의 노력들로 범죄를 척결하자\", flatten=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 최대 점수 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['국제사회', '와', '우리', '의', '노력', '들로', '범죄', '를', '척결', '하자']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.tokenizer import MaxScoreTokenizer\n",
    "\n",
    "maxscore_tokenizer = MaxScoreTokenizer(scores=scores)\n",
    "maxscore_tokenizer.tokenize(\"국제사회와우리의노력들로범죄를척결하자\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. SOYNLP 반복되는 문자 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아ㅋㅋ영화존잼쓰ㅠㅠ\n",
      "아ㅋㅋ영화존잼쓰ㅠㅠ\n",
      "아ㅋㅋ영화존잼쓰ㅠㅠ\n",
      "아ㅋㅋ영화존잼쓰ㅠㅠ\n"
     ]
    }
   ],
   "source": [
    "from soynlp.normalizer import *\n",
    "\n",
    "print(emoticon_normalize('앜ㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠ', num_repeats=2))\n",
    "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠ', num_repeats=2))\n",
    "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠ', num_repeats=2))\n",
    "print(emoticon_normalize('앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ이영화존잼쓰ㅠㅠㅠㅠㅠㅠㅠㅠ', num_repeats=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "와하하핫\n",
      "와하하핫\n",
      "와하하핫\n"
     ]
    }
   ],
   "source": [
    "print(repeat_normalize('와하하하하하하하하하핫', num_repeats=2))\n",
    "print(repeat_normalize('와하하하하하하핫', num_repeats=2))\n",
    "print(repeat_normalize('와하하하하핫', num_repeats=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customized KoNLPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install customized_konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/yeonii/lib/python3.8/site-packages/konlpy/tag/_okt.py:17: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['메', '연', '이', '는', '딥', '러닝', '공부', '중이', '에요', '.']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ckonlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "twitter.morphs('메연이는 딥러닝 공부중이에요.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter.add_dictionary('메연이', 'Noun')\n",
    "twitter.add_dictionary('딥러닝', 'Noun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['메연이', '는', '딥러닝', '공부', '중이', '에요', '.']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.morphs('메연이는 딥러닝 공부중이에요.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 문장 토큰화 : ['딥 러닝 자연어 처리가 재미있기는 합니다.', '그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다.', '이제 해보면 알걸요?']\n"
     ]
    }
   ],
   "source": [
    "import mecab_ko_dic\n",
    "import kss\n",
    "\n",
    "text_kor1 = '딥 러닝 자연어 처리가 재미있기는 합니다. 그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다. 이제 해보면 알걸요?'\n",
    "\n",
    "print('한국어 문장 토큰화 :',kss.split_sentences(text_kor1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KoNLPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "꼬꼬마 형태소 분석 : ['같', '은', '날', '피고인', '2', '에게', '그중', '여행용', '가방', '과', '현금', '1', '억', '9,600', '만', '원', '을', '전달', '하', '였', '다', '.']\n",
      "꼬꼬마 품사 태깅 : [('같', 'VA'), ('은', 'ETD'), ('날', 'NNG'), ('피고인', 'NNG'), ('2', 'NR'), ('에게', 'JKM'), ('그중', 'NNG'), ('여행용', 'NNG'), ('가방', 'NNG'), ('과', 'JKM'), ('현금', 'NNG'), ('1', 'NR'), ('억', 'NR'), ('9,600', 'NR'), ('만', 'NR'), ('원', 'NNM'), ('을', 'JKO'), ('전달', 'NNG'), ('하', 'XSV'), ('였', 'EPT'), ('다', 'EFN'), ('.', 'SF')]\n",
      "꼬꼬마 명사 추출 : ['날', '피고인', '2', '그중', '여행용', '가방', '현금', '1', '1억', '억', '9,600', '9,600만', '만', '원', '전달']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "\n",
    "text_kor2 = \"같은 날 피고인 2에게 그중 여행용 가방과 현금 1억 9,600만 원을 전달하였다.\"\n",
    "\n",
    "print('꼬꼬마 형태소 분석 :',kkma.morphs(text_kor2))\n",
    "print('꼬꼬마 품사 태깅 :',kkma.pos(text_kor2))\n",
    "print('꼬꼬마 명사 추출 :',kkma.nouns(text_kor2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKT 형태소 분석 : ['같은', '날', '피고인', '2', '에게', '그중', '여행', '용', '가방', '과', '현금', '1억', '9,600만', '원', '을', '전달', '하였다', '.']\n",
      "OKT 품사 태깅 : [('같은', 'Adjective'), ('날', 'Noun'), ('피고인', 'Noun'), ('2', 'Number'), ('에게', 'Josa'), ('그중', 'Adverb'), ('여행', 'Noun'), ('용', 'Noun'), ('가방', 'Noun'), ('과', 'Josa'), ('현금', 'Noun'), ('1억', 'Number'), ('9,600만', 'Number'), ('원', 'Noun'), ('을', 'Josa'), ('전달', 'Noun'), ('하였다', 'Verb'), ('.', 'Punctuation')]\n",
      "OKT 명사 추출 : ['날', '피고인', '여행', '용', '가방', '현금', '원', '전달']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "print('OKT 형태소 분석 :',okt.morphs(text_kor2))\n",
    "print('OKT 품사 태깅 :',okt.pos(text_kor2))\n",
    "print('OKT 명사 추출 :',okt.nouns(text_kor2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Komoran 형태소 분석 : ['같', '은', '날', '피고인', '2', '에게', '그중', '여행', '용', '가방', '과', '현금', '1', '억', '9', ',', '600', '만', '원', '을', '전달', '하', '았', '다', '.']\n",
      "Komoran 품사 태깅 : [('같', 'VA'), ('은', 'ETM'), ('날', 'NNG'), ('피고인', 'NNP'), ('2', 'SN'), ('에게', 'JKB'), ('그중', 'NNG'), ('여행', 'NNG'), ('용', 'XSN'), ('가방', 'NNG'), ('과', 'JC'), ('현금', 'NNP'), ('1', 'SN'), ('억', 'NR'), ('9', 'SN'), (',', 'SP'), ('600', 'SN'), ('만', 'NR'), ('원', 'NNB'), ('을', 'JKO'), ('전달', 'NNG'), ('하', 'XSV'), ('았', 'EP'), ('다', 'EF'), ('.', 'SF')]\n",
      "Komoran 명사 추출 : ['날', '피고인', '그중', '여행', '가방', '현금', '원', '전달']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Komoran\n",
    "komoran = Komoran()\n",
    "\n",
    "print('Komoran 형태소 분석 :',komoran.morphs(text_kor2))\n",
    "print('Komoran 품사 태깅 :',komoran.pos(text_kor2))\n",
    "print('Komoran 명사 추출 :',komoran.nouns(text_kor2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hannanum 형태소 분석 : ['같', '은', '나', 'ㄹ', '피고', '이', 'ㄴ', '2', '에게', '그중', '여행용', '가방', '과', '현금', '1억', '9,600', '만', '원', '을', '전달', '하', '었다', '.']\n",
      "Hannanum 품사 태깅 : [('같', 'P'), ('은', 'E'), ('나', 'P'), ('ㄹ', 'E'), ('피고', 'N'), ('이', 'J'), ('ㄴ', 'E'), ('2', 'N'), ('에게', 'J'), ('그중', 'M'), ('여행용', 'N'), ('가방', 'N'), ('과', 'J'), ('현금', 'N'), ('1억', 'N'), ('9,600', 'N'), ('만', 'J'), ('원', 'N'), ('을', 'J'), ('전달', 'N'), ('하', 'X'), ('었다', 'E'), ('.', 'S')]\n",
      "Hannanum 명사 추출 : ['피고', '2', '여행용', '가방', '현금', '1억', '9,600', '원', '전달']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Hannanum\n",
    "hannanum = Hannanum()\n",
    "\n",
    "print('Hannanum 형태소 분석 :',hannanum.morphs(text_kor2))\n",
    "print('Hannanum 품사 태깅 :',hannanum.pos(text_kor2))\n",
    "print('Hannanum 명사 추출 :',hannanum.nouns(text_kor2)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b09d487f58830ae36779bc7e2c4986ef97a22d0a201d00a8669188d9fddafca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
